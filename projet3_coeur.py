# -*- coding: utf-8 -*-
"""Projet3_coeur.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OzMmMa54CbzkOF5HTFCyIUhewZp8OIn6

# IMPORT
"""

import pandas as pd
df = pd.read_csv('https://raw.githubusercontent.com/MaskiVal/DataSets/main/heartDisease.csv')

"""# Exploration"""

df

df['target'].value_counts()

"""# Suppression du doublon"""

df = df.drop([163])

"""# Equilibrer le dataframe"""

from imblearn.over_sampling import RandomOverSampler
from sklearn.datasets import make_classification

X = df.drop('target', axis = 1)

y = df['target']

ros = RandomOverSampler(random_state = 42)

X_resampled, y_resampled = ros.fit_resample(X, y)

print(X_resampled)
print(y_resampled)

X_resampled['target'] = y_resampled

X_resampled['target'].value_counts()

df = X_resampled

df.describe()

df

"""# Tests Kruskal-Wallis"""

from scipy import stats
stats.kruskal(df['age'][df['target'] == 0], df['age'][df['target'] == 1])

stats.kruskal(df['sex'][df['target'] == 0], df['sex'][df['target'] == 1])

stats.kruskal(df['cp'][df['target'] == 0], df['cp'][df['target'] == 1])

stats.kruskal(df['trestbps'][df['target'] == 0], df['trestbps'][df['target'] == 1])

stats.kruskal(df['chol'][df['target'] == 0], df['chol'][df['target'] == 1])

stats.kruskal(df['fbs'][df['target'] == 0], df['fbs'][df['target'] == 1])

stats.kruskal(df['thalach'][df['target'] == 0], df['thalach'][df['target'] == 1])

stats.kruskal(df['exang'][df['target'] == 0], df['exang'][df['target'] == 1])

stats.kruskal(df['oldpeak'][df['target'] == 0], df['oldpeak'][df['target'] == 1])

stats.kruskal(df['slope'][df['target'] == 0], df['slope'][df['target'] == 1])

stats.kruskal(df['ca'][df['target'] == 0], df['ca'][df['target'] == 1])

stats.kruskal(df['thal'][df['target'] == 0], df['thal'][df['target'] == 1])

"""Après application du test de Kruskal-Wallis, on s'aperçoit qu'il n'y qu'une variable pour laquelle on ne peut pas rejeter l'hypothèse nulle selon laquelle  la médiane est la même selon que le patient soit malade ou non : 'fbs' (Sucre dans le sang à jeun).

# Distribution des données
"""

import matplotlib.pyplot as plt
import seaborn as sns

fig, axes = plt.subplots(5, 3, figsize=(14, 18))
plt.subplots_adjust(hspace=0.5)

axes[0, 0].boxplot(df['age'])
axes[0, 0].set_title('Age')

axes[0, 1].boxplot(df['sex'])
axes[0, 1].set_title('Sex')

axes[0, 2].boxplot(df['cp'])
axes[0, 2].set_title('Cp')

axes[1, 0].boxplot(df['trestbps'])
axes[1, 0].set_title('Trestbps')

axes[1, 1].boxplot(df['chol'])
axes[1, 1].set_title('Chol')

axes[1, 2].boxplot(df['fbs'])
axes[1, 2].set_title('Fbs')

axes[2, 0].boxplot(df['restecg'])
axes[2, 0].set_title('Restecg')

axes[2, 1].boxplot(df['thalach'])
axes[2, 1].set_title('Thalach')

axes[2, 2].boxplot(df['exang'])
axes[2, 2].set_title('Exang')

axes[3, 0].boxplot(df['oldpeak'])
axes[3, 0].set_title('Oldpeak')

axes[3, 1].boxplot(df['slope'])
axes[3, 1].set_title('Slope')

axes[3, 2].boxplot(df['ca'])
axes[3, 2].set_title('Ca')

axes[4, 0].boxplot(df['thal'])
axes[4, 0].set_title('Thal')

plt.show()

"""# Corrélations"""

df_corr = df.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(df_corr, annot=True, cmap="coolwarm", fmt=".2f", linewidths=.5)

plt.show()

"""On constate en observant le tableau de corrélations qu'il n'existe pas de variables suffisamment corrélées entre elles pour justifier leur suppression éventuelle.

# Preprocessing ML
"""

from sklearn.model_selection import train_test_split
#pour les différents Scaler
from sklearn.preprocessing import MaxAbsScaler, QuantileTransformer, PowerTransformer, MinMaxScaler, StandardScaler, RobustScaler
#pour les différents modèles de ML
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.svm import LinearSVC

#pour les metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import recall_score

pip install pycaret

from pycaret.classification import *
exp = setup(df, target='target')

df.to_csv('df_coeur.csv')

compare_models()

#listes

##liste des Scalers utilisés
list_scalers = [
    MaxAbsScaler(),
    QuantileTransformer(),
    PowerTransformer(),
    MinMaxScaler(),
    StandardScaler(),
    RobustScaler()
]
##liste des modèles utilisés
list_models = [
    KNeighborsClassifier(),
    DecisionTreeClassifier(),
    LogisticRegression(),
    ExtraTreesClassifier(),
    RandomForestClassifier(),
    GradientBoostingClassifier(),
    AdaBoostClassifier(),
    XGBClassifier(),
    LGBMClassifier(verbose=-1)
]

X = df.drop('target', axis = 1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Test de l'ensemble des modèles"""

for model in list_models:
    print('__________________________')
    print(model.__class__.__name__)
    print('__________________________')
    print(' ')
    print('Paramètres du ML : ', model)
    print(' ')

    for scaler in list_scalers:
        print(f"=== {scaler.__class__.__name__} ===")
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        model.fit(X_train_scaled, y_train)

        y_pred_test = model.predict(X_test_scaled)

        print('Accuracy score Train: ', model.score(X_train_scaled, y_train))
        print('Accuracy score Test: ', model.score(X_test_scaled, y_test))
        print('Recall Test: ', recall_score(y_test, y_pred_test))
        print('Overfitting : ', (model.score(X_train_scaled, y_train) - model.score(X_test_scaled, y_test)))


        confusion_mat = confusion_matrix(y_test, y_pred_test)
        matrice = pd.DataFrame(data = confusion_mat,
                 index = model.classes_ ,
                 columns = model.classes_)
        print(matrice)
        print(' ')

"""# Top 3 Model"""

from sklearn.model_selection import cross_val_score

#double boucle
results = []
for model in list_models:

    for scaler in list_scalers:

        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        model.fit(X_train_scaled, y_train)

        accuracy_train = model.score(X_train_scaled, y_train)
        accuracy_test = model.score(X_test_scaled, y_test)

        y_pred_test = model.predict(X_test_scaled)

        recall_test = recall_score(y_test, y_pred_test)

        overfitting = (model.score(X_train_scaled, y_train) - model.score(X_test_scaled, y_test))

        scores = cross_val_score(model, X_train_scaled, y_train, scoring='recall', cv=5)
        avg_scores = scores.mean()

        confusion_mat = confusion_matrix(y_test, y_pred_test)
        matrice = pd.DataFrame(data = confusion_mat,
                 index = model.classes_ ,
                 columns = model.classes_)
        results.append((model.__class__.__name__, scaler.__class__.__name__, accuracy_train, accuracy_test, recall_test, overfitting, avg_scores, matrice))

#tris de la liste results en fonction du recall_test
sorted_results = sorted(results, key=lambda x: x[6], reverse=True)

for model, scaler, accuracy_train, accuracy_test, recall_test, overfitting, avg_scores, matrice in sorted_results:
    print("___________________________")
    print(f"Model: {model}")
    print(f"Scaler: {scaler}")
    print(f"Avg scores - cross validation : {avg_scores}")
    print(f"Accuracy Train: {accuracy_train}")
    print(f"Accuracy Test: {accuracy_test}")
    print(f"Recall Test: {recall_test}")
    print(f"Overfitting: {overfitting}")
    print(matrice)

"""# Grid SearchCV"""

from sklearn.model_selection import GridSearchCV

scaler = MaxAbsScaler()

X = df.drop('target', axis = 1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

hyperparam = [{'learning_rate' : [1, 0.1, 0.01, 0.001],
               'max_depth': [2, 4, 6, 8, 10, 12],
               'min_child_weight' : [0, 1, 3, 5, 7, 9],
               'gamma': [0, 0.1, 0.2, 0.4, 0.6, 0.8],
               'colsample_bytree': [0.3, 0.5, 0.7, 0.9]}]

grid = GridSearchCV(XGBClassifier(), hyperparam, cv = 5, scoring = 'recall')

grid.fit(X_train_scaled, y_train)

pd.DataFrame(grid.cv_results_)

grid.best_params_

modele = grid.best_estimator_

y_pred = modele.predict(X_test_scaled)

accuracy_score(y_pred, y_test)

recall_score(y_pred, y_test)

scores = cross_val_score(modele, X_train_scaled, y_train, scoring='recall', cv=5)
avg_scores = scores.mean()

avg_scores

"""# Algorithme final"""

XGB = XGBClassifier(colsample_bytree= 0.5,
 gamma= 0,
 learning_rate= 0.01,
 max_depth= 6,
 min_child_weight= 0)

XGB.fit(X_train_scaled, y_train)

y_pred = XGB.predict(X_test_scaled)

accuracy_score(y_pred, y_test)

recall_score(y_pred, y_test)

scores = cross_val_score(XGB, X_train_scaled, y_train, scoring='recall', cv=5)
avg_scores = scores.mean()
avg_scores

scores1 = cross_val_score(XGB, X_train_scaled, y_train, scoring='accuracy', cv=5)
avg_scores1 = scores1.mean()
avg_scores1

"""# Shap"""

pip install shap

import shap

X_test_shape = pd.DataFrame(X_test_scaled, columns=list(X_test.columns))
X_train_shape = pd.DataFrame(X_train_scaled, columns=list(X_train.columns))

xgb2 = XGBClassifier()

xgb2.fit(X_train_scaled, y_train)

explainer = shap.KernelExplainer(xgb2.predict,shap.sample(X_test_shape,100))

shap_values = explainer.shap_values(X_test_shape,nsamples=100)

shap.summary_plot(shap_values,X_test_shape)

shap.initjs()
num_test = 2
shap.force_plot(explainer.expected_value, shap_values[num_test,:], X_test_scaled[num_test,:].round(3), feature_names=X.columns, matplotlib=True, show=True)
plt.savefig('force_plot.png')

"""#Lasso"""

from sklearn.linear_model import LassoCV

reg = LassoCV()
reg.fit(X_train_scaled, y_train)

print("Best score using built-in LassoCV: %f" %reg.score(X_train_scaled,y_train))
coef = pd.Series(reg.coef_, index = X_train.columns)
print("Lasso picked " + str(sum(coef != 0)) + " variables and eliminated the other " +  str(sum(coef == 0)) + " variables")

fig = plt.figure(figsize=(6,6))
imp_coef = coef.sort_values()
plt.rcParams['figure.figsize'] = (8.0, 10.0)
imp_coef.plot(kind = "barh")
plt.axvline(x=0, color='g')
plt.title("Importance des variables en utilisation un modèle Lasso")
fig.savefig('importance_graph.png', dpi=200, bbox_inches = 'tight') ;