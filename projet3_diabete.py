# -*- coding: utf-8 -*-
"""Projet3_diabete.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sUjUwRZp3r7ETOUUEUGZw0UciSwh3AcZ

# IMPORT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

link_diabete = " https://raw.githubusercontent.com/MaskiVal/DataSets/main/diabetes.csv"

df_diabete = pd.read_csv(link_diabete)
df_diabete

"""# Exploration"""

df_diabete.info()

df_diabete.describe()

df_diabete['Outcome'].value_counts()

"""# Remplacement des 0"""

from scipy.stats import skew

df_diabete['BloodPressure'][df_diabete['BloodPressure'] != 0].skew(axis = 0, skipna = True)

df_diabete['Glucose'][df_diabete['Glucose'] != 0].skew(axis = 0, skipna = True)

df_diabete['Insulin'][df_diabete['Insulin'] != 0].skew(axis = 0, skipna = True)

df_diabete['BMI'][df_diabete['BMI'] != 0].skew(axis = 0, skipna = True)

df_diabete['SkinThickness'][df_diabete['SkinThickness'] != 0].skew(axis = 0, skipna = True)

moyennes = df_diabete[df_diabete['Glucose'] != 0].groupby('Outcome')['Glucose'].mean()
df_diabete['Outcome'] = df_diabete['Outcome'].astype(float)
df_diabete['Glucose'] = df_diabete.apply(lambda row: moyennes[row['Outcome']] if row['Glucose'] == 0 else row['Glucose'], axis=1)

moyennes = df_diabete[df_diabete['BloodPressure'] != 0].groupby('Outcome')['BloodPressure'].median()
df_diabete['BloodPressure'] = df_diabete.apply(lambda row: moyennes[row['Outcome']] if row['BloodPressure'] == 0 else row['BloodPressure'], axis=1)

moyennes = df_diabete[df_diabete['Insulin'] != 0].groupby('Outcome')['Insulin'].mean()
df_diabete['Insulin'] = df_diabete.apply(lambda row: moyennes[row['Outcome']] if row['Insulin'] == 0 else row['Insulin'], axis=1)

moyennes = df_diabete[df_diabete['BMI'] != 0].groupby('Outcome')['BMI'].mean()
df_diabete['BMI'] = df_diabete.apply(lambda row: moyennes[row['Outcome']] if row['BMI'] == 0 else row['BMI'], axis=1)

moyennes = df_diabete[df_diabete['SkinThickness'] != 0].groupby('Outcome')['SkinThickness'].mean()
df_diabete['SkinThickness'] = df_diabete.apply(lambda row: moyennes[row['Outcome']] if row['SkinThickness'] == 0 else row['SkinThickness'], axis=1)

"""# Equilibrer le data set"""

from imblearn.over_sampling import RandomOverSampler
from sklearn.datasets import make_classification

X = df_diabete[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]

Y = df_diabete['Outcome']

ros = RandomOverSampler(random_state = 42)

X_resampled, y_resampled = ros.fit_resample(X, Y)

print(X_resampled)
print(y_resampled)

X_resampled['Outcome'] = y_resampled

X_resampled['Outcome'].value_counts()

X_resampled.describe()

"""# Tests Kruskal-Wallis"""

from scipy import stats
stats.kruskal(X_resampled['Pregnancies'][X_resampled['Outcome'] == 0], X_resampled['Pregnancies'][X_resampled['Outcome'] == 1])

stats.kruskal(X_resampled['Glucose'][X_resampled['Outcome'] == 0], X_resampled['Glucose'][X_resampled['Outcome'] == 1])

stats.kruskal(X_resampled['BloodPressure'][X_resampled['Outcome'] == 0], X_resampled['BloodPressure'][X_resampled['Outcome'] == 1])

stats.kruskal(X_resampled['SkinThickness'][X_resampled['Outcome'] == 0], X_resampled['SkinThickness'][X_resampled['Outcome'] == 1])

stats.kruskal(X_resampled['BMI'][X_resampled['Outcome'] == 0], X_resampled['BMI'][X_resampled['Outcome'] == 1])

stats.kruskal(X_resampled['DiabetesPedigreeFunction'][X_resampled['Outcome'] == 0], X_resampled['DiabetesPedigreeFunction'][X_resampled['Outcome'] == 1])

stats.kruskal(X_resampled['Age'][X_resampled['Outcome'] == 0], X_resampled['Age'][X_resampled['Outcome'] == 1])

stats.kruskal(X_resampled['Insulin'][X_resampled['Outcome'] == 0], X_resampled['Insulin'][X_resampled['Outcome'] == 1])

"""Comme le test de Krustal-Wallis est très inférieur à 0.05 pour chacune des variables, on peut en toute confiance rejeter l'hypothèse nulle selon laquelle la médiane de chacune des variables est la même selon que le patient soit malade ou non.

# Distribution des données
"""

fig, axes = plt.subplots(3, 3, figsize=(14, 18))
plt.subplots_adjust(hspace=0.5)

axes[0, 0].boxplot(X_resampled['Pregnancies'])
axes[0, 0].set_title('Pregnancies')

axes[0, 1].boxplot(X_resampled['Glucose'])
axes[0, 1].set_title('Glucose')

axes[0, 2].boxplot(X_resampled['BloodPressure'])
axes[0, 2].set_title('BloodPressure')

axes[1, 0].boxplot(X_resampled['SkinThickness'])
axes[1, 0].set_title('SkinThickness')

axes[1, 1].boxplot(X_resampled['Insulin'])
axes[1, 1].set_title('Insulin')

axes[1, 2].boxplot(X_resampled['BMI'])
axes[1, 2].set_title('BMI')

axes[2, 0].boxplot(X_resampled['DiabetesPedigreeFunction'])
axes[2, 0].set_title('DiabetesPedigreeFunction')

axes[2, 1].boxplot(X_resampled['Age'])
axes[2, 1].set_title('Age')

axes[2, 2].boxplot(X_resampled['Outcome'])
axes[2, 2].set_title('Outcome')

plt.show()

"""# Corrélations"""

sns.pairplot(X_resampled)
plt.show()
X_resampled_corr = X_resampled.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(X_resampled_corr, annot=True, cmap="coolwarm", fmt=".2f", linewidths=.5)

plt.show()

"""On constate en observant le tableau de corrélations qu'il n'existe pas de variables suffisamment corrélées entre elles pour justifier leur suppression éventuelle.

---

# Preprocessing ML
"""

pip install lightgbm

from sklearn.model_selection import train_test_split
#pour les différents Scaler
from sklearn.preprocessing import MaxAbsScaler, QuantileTransformer, PowerTransformer, MinMaxScaler, StandardScaler, RobustScaler
#pour les différents modèles de ML
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from sklearn.svm import LinearSVC

#pour les metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import recall_score

df_diabete = X_resampled

pip install pycaret

from pycaret.classification import *
exp = setup(df_diabete, target='Outcome')

df_diabete.to_csv('df_diabete.csv')

compare_models()

#listes

##liste des Scalers utilisés
list_scalers = [
    MaxAbsScaler(),
    QuantileTransformer(),
    PowerTransformer(),
    MinMaxScaler(),
    StandardScaler(),
    RobustScaler()
]
##liste des modèles utilisés
list_models = [
    KNeighborsClassifier(),
    DecisionTreeClassifier(),
    LogisticRegression(),
    ExtraTreesClassifier(),
    RandomForestClassifier(),
    GradientBoostingClassifier(),
    AdaBoostClassifier(),
    XGBClassifier(),
    LGBMClassifier(verbose=-1)
]

X = df_diabete.drop('Outcome', axis = 1)
y = df_diabete['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

"""# Test de l'ensemble des modèles"""

for model in list_models:
    print('__________________________')
    print(model.__class__.__name__)
    print('__________________________')
    print(' ')
    print('Paramètres du ML : ', model)
    print(' ')

    for scaler in list_scalers:
        print(f"=== {scaler.__class__.__name__} ===")
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        model.fit(X_train_scaled, y_train)

        y_pred_test = model.predict(X_test_scaled)

        print('Accuracy score Train: ', model.score(X_train_scaled, y_train))
        print('Accuracy score Test: ', model.score(X_test_scaled, y_test))
        print('Recall Test: ', recall_score(y_test, y_pred_test))
        print('Overfitting : ', (model.score(X_train_scaled, y_train) - model.score(X_test_scaled, y_test)))


        confusion_mat = confusion_matrix(y_test, y_pred_test)
        matrice = pd.DataFrame(data = confusion_mat,
                 index = model.classes_ ,
                 columns = model.classes_)
        print(matrice)
        print(' ')

"""# Top 3 ML"""

from sklearn.model_selection import cross_val_score

#double boucle
results = []
for model in list_models:

    for scaler in list_scalers:

        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        model.fit(X_train_scaled, y_train)

        accuracy_train = model.score(X_train_scaled, y_train)
        accuracy_test = model.score(X_test_scaled, y_test)

        y_pred_test = model.predict(X_test_scaled)

        recall_test = recall_score(y_test, y_pred_test)

        overfitting = (model.score(X_train_scaled, y_train) - model.score(X_test_scaled, y_test))

        scores = cross_val_score(model, X_train_scaled, y_train, scoring='recall', cv=5)
        avg_scores = scores.mean()

        confusion_mat = confusion_matrix(y_test, y_pred_test)
        matrice = pd.DataFrame(data = confusion_mat,
                 index = model.classes_ ,
                 columns = model.classes_)
        results.append((model.__class__.__name__, scaler.__class__.__name__, accuracy_train, accuracy_test, recall_test, overfitting, avg_scores, matrice))

#tris de la liste results en fonction du recall_test
sorted_results = sorted(results, key=lambda x: x[6], reverse=True)

for model, scaler, accuracy_train, accuracy_test, recall_test, overfitting, avg_scores, matrice in sorted_results:
    print("___________________________")
    print(f"Model: {model}")
    print(f"Scaler: {scaler}")
    print(f"Avg scores - cross validation : {avg_scores}")
    print(f"Accuracy Train: {accuracy_train}")
    print(f"Accuracy Test: {accuracy_test}")
    print(f"Recall Test: {recall_test}")
    print(f"Overfitting: {overfitting}")
    print(matrice)

"""# Grid SearchCV"""

from sklearn.model_selection import GridSearchCV

scaler = QuantileTransformer()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

hyperparam = [{'n_estimators': [10, 15, 20, 25, 35, 50],
                'criterion' : ['gini', 'entropy', 'log_loss'],
                'max_features' : ['sqrt', 'log2', 'None'],
               'min_samples_leaf': [1, 2, 4, 6, 8, 16]}]

grid = GridSearchCV(RandomForestClassifier(),
                    hyperparam,
                    cv = 5,
                    scoring = 'recall',
                    return_train_score = True)

grid.fit(X_train_scaled, y_train)

result = pd.DataFrame(grid.cv_results_).sort_values(by='mean_test_score', ascending=False)

result

result.iloc[253].params

"""# Algorithme final"""

modelRF = RandomForestClassifier(criterion ='entropy',
                                max_features = None,
                                min_samples_leaf= 1,
                                n_estimators= 15)

modelRF.fit(X_train_scaled, y_train)

y_pred = modelRF.predict(X_test_scaled)

accuracy_score(y_pred, y_test)

recall_score(y_pred, y_test)

scores = cross_val_score(modelRF, X_train_scaled, y_train, scoring='recall', cv=10)
avg_scores = scores.mean()

scores1 = cross_val_score(modelRF, X_train_scaled, y_train, scoring='accuracy', cv=10)
avg_scores1 = scores1.mean()

avg_scores1

avg_scores

"""# Shap"""

pip install shap

X_test_shape = pd.DataFrame(X_test_scaled, columns=list(X_test.columns))
X_train_shape = pd.DataFrame(X_train_scaled, columns=list(X_train.columns))

rfc = RandomForestClassifier()

rfc.fit(X_train_scaled, y_train)

X_test_shape

import shap

explainer = shap.KernelExplainer(rfc.predict,shap.sample(X_test_shape,100))

shap_values = explainer.shap_values(X_test_shape,nsamples=100)

shap.summary_plot(shap_values,X_test_shape)

shap.initjs()
num_test = 2
shap.force_plot(explainer.expected_value, shap_values[num_test,:], X_test_scaled[num_test,:].round(3), feature_names=X.columns, matplotlib=True, show=True)
plt.savefig('force_plot.png')

"""#Lasso"""

from sklearn.linear_model import LassoCV

reg = LassoCV()
reg.fit(X_train_scaled, y_train)

print("Best score using built-in LassoCV: %f" %reg.score(X_train_scaled,y_train))
coef = pd.Series(reg.coef_, index = X_train.columns)
print("Lasso picked " + str(sum(coef != 0)) + " variables and eliminated the other " +  str(sum(coef == 0)) + " variables")

fig = plt.figure(figsize=(6,6))
imp_coef = coef.sort_values()
plt.rcParams['figure.figsize'] = (8.0, 10.0)
imp_coef.plot(kind = "barh")
plt.axvline(x=0, color='g')
plt.title("Importance des variables en utilisation un modèle Lasso")
fig.savefig('importance_graph.png', dpi=200, bbox_inches = 'tight') ;