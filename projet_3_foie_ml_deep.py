# -*- coding: utf-8 -*-
"""Projet_3_foie_ML_DEEP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ta0B1f5kUoHvG-KsBYefzWpL1DdtAem9

# IMPORT
"""

import pandas as pd
import numpy as np
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from scipy.stats import skew
from statannot import add_stat_annotation
from scipy import stats

from ydata_profiling import ProfileReport

from sklearn.model_selection import train_test_split
#pour les différents Scaler
from sklearn.preprocessing import MaxAbsScaler, QuantileTransformer, PowerTransformer, MinMaxScaler, StandardScaler, RobustScaler
#pour les différents modèles de ML
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier
from sklearn.svm import LinearSVC, NuSVC, SVC
from sklearn.naive_bayes import GaussianNB
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier
from imblearn.over_sampling import RandomOverSampler, SMOTE

from sklearn.neural_network import MLPClassifier


#pour les metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import recall_score, make_scorer


# pour les hyperparalmètres
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

# Pour les explications de modeles
from sklearn.linear_model import LassoCV
import shap
from sklearn.inspection import permutation_importance

# Pour le DEEP LEARNING
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

link_foie = "https://raw.githubusercontent.com/MaskiVal/DataSets/main/liver_patient.csv"

df_foie = pd.read_csv(link_foie)
df_foie.sample(20)

"""# Exploration"""

df_foie.info()

df_foie[df_foie['Albumin_and_Globulin_Ratio'].isna()==True]

df_foie.describe()

profile = ProfileReport(df_foie, title="Report_maladie_du_foie")

profile.to_widgets()

profile.to_notebook_iframe()

"""# Detection des duplicates et drop"""

doublons = df_foie.duplicated()
print(df_foie[doublons])

df_foie.drop_duplicates(inplace=True)

df_foie.info()

"""# Remplacement des NaN"""

skewness_value = df_foie['Albumin_and_Globulin_Ratio'].skew()

print("Skewness:", skewness_value)

"""la skewness est skewed, on utilisera la moyenne pour le fillna des nan dans Albumin_and_Globulin_Ratio

"""

df_foie['Albumin_and_Globulin_Ratio'].fillna(df_foie['Albumin_and_Globulin_Ratio'].mean(), inplace = True)

df_foie.info()

"""# Creation de la colonne genre factorisée"""

df_foie['fact_Gender'] = df_foie['Gender'].factorize()[0]

df_foie.info()

df_foie['fact_Gender'].value_counts()

"""# Distribution des données & Corrélations

## Distribution
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

fig, axes = plt.subplots(5, 2, figsize=(14, 18))
plt.subplots_adjust(hspace=0.5)

axes[0, 0].boxplot(df_foie['Age'])
axes[0, 0].set_title('Age')

axes[0, 1].boxplot(df_foie['Dataset'])
axes[0, 1].set_title('Dataset')

axes[1, 0].boxplot(df_foie['Total_Bilirubin'])
axes[1, 0].set_title('Total_Bilirubin')

axes[1, 1].boxplot(df_foie['Direct_Bilirubin'])
axes[1, 1].set_title('Direct_Bilirubin')

axes[2, 0].boxplot(df_foie['Alkaline_Phosphotase'])
axes[2, 0].set_title('Alkaline_Phosphotase')

axes[2, 1].boxplot(df_foie['Alamine_Aminotransferase'])
axes[2, 1].set_title('Alamine_Aminotransferase')

axes[3, 0].boxplot(df_foie['Aspartate_Aminotransferase'])
axes[3, 0].set_title('Aspartate_Aminotransferase')

axes[3, 1].boxplot(df_foie['Total_Protiens'])
axes[3, 1].set_title('Total_Protiens')

axes[4, 0].boxplot(df_foie['Albumin'])
axes[4, 0].set_title('Albumin')

axes[4, 1].boxplot(df_foie['Albumin_and_Globulin_Ratio'])
axes[4, 1].set_title('Albumin_and_Globulin_Ratio')



plt.show()

"""la colonne dataset : le 1 signifie Malade , le 2 signifie Sain"""

fig, axes = plt.subplots(5, 2, figsize=(14, 18))
plt.subplots_adjust(hspace=0.5)

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Age'], ax=axes[0, 0])
axes[0, 0].set_title('Age')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Total_Bilirubin'], ax=axes[0, 1])
axes[0, 1].set_title('Total_Bilirubin')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Direct_Bilirubin'], ax=axes[1, 0])
axes[1, 0].set_title('Direct_Bilirubin')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Alkaline_Phosphotase'], ax=axes[1, 1])
axes[1, 1].set_title('Alkaline_Phosphotase')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Alamine_Aminotransferase'], ax=axes[2, 0])
axes[2, 0].set_title('Alamine_Aminotransferase')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Aspartate_Aminotransferase'], ax=axes[2, 1])
axes[2, 1].set_title('Aspartate_Aminotransferase')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Total_Protiens'], ax=axes[3, 0])
axes[3, 0].set_title('Total_Protiens')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Albumin'], ax=axes[3, 1])
axes[3, 1].set_title('Albumin')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['Albumin_and_Globulin_Ratio'], ax=axes[4, 0])
axes[4, 0].set_title('Albumin_and_Globulin_Ratio')

sns.boxplot(x=df_foie['Dataset'], y=df_foie['fact_Gender'], ax=axes[4, 1])
axes[4, 1].set_title('fact_Gender')


plt.show()

"""## Corrélation

### Analyse générale
"""

sns.pairplot(df_foie, hue = 'Dataset')
plt.show()

plt.figure(figsize=(8, 6))
sns.heatmap(df_foie.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=.5)

plt.show()

"""### Drop les colonnes trop corrélées : Direct_Bilirubin, Aspartate_Aminotransferase, Total_Protiens et Albumin

"""

df_foie.info()

df_foie.drop(columns = ['Direct_Bilirubin', 'Aspartate_Aminotransferase', 'Total_Protiens', 'Albumin'], inplace = True)

df_foie.info()

plt.figure(figsize=(8, 6))
sns.heatmap(df_foie.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=.5)

plt.show()

"""# Statistiques

Le diagnostic ('Dataset') doit etre un string
"""

df_foie['Dataset_str'] = df_foie['Dataset'].astype(str)

df_foie.info()

fig, axes = plt.subplots(3, 2, figsize=(14, 18))
plt.subplots_adjust(hspace=0.5)

def add_stat_annotations(x, y, ax):
    add_stat_annotation(data=df_foie, x=x, y=y, ax=ax, box_pairs=[('1', '2')],
                     perform_stat_test=True, test='Kruskal', text_format='star', loc='outside', verbose=2)



sns.boxplot(x=df_foie['Dataset_str'], y=df_foie['Age'], ax=axes[0, 0])
axes[0, 0].set_title('Age')
add_stat_annotations('Dataset_str', 'Age', axes[0, 0])


sns.boxplot(x=df_foie['Dataset_str'], y=df_foie['Total_Bilirubin'], ax=axes[0, 1])
axes[0, 1].set_title('Total_Bilirubin')
add_stat_annotations('Dataset_str', 'Total_Bilirubin', axes[0, 1])

sns.boxplot(x=df_foie['Dataset_str'], y=df_foie['Alkaline_Phosphotase'], ax=axes[1, 0])
axes[1, 0].set_title('Alkaline_Phosphotase')
add_stat_annotations('Dataset_str', 'Alkaline_Phosphotase', axes[1, 0])

sns.boxplot(x=df_foie['Dataset_str'], y=df_foie['Alamine_Aminotransferase'], ax=axes[1, 1])
axes[1, 1].set_title('Alamine_Aminotransferase')
add_stat_annotations('Dataset_str', 'Alamine_Aminotransferase', axes[1, 1])

sns.boxplot(x=df_foie['Dataset_str'], y=df_foie['Albumin_and_Globulin_Ratio'], ax=axes[2, 0])
axes[2, 0].set_title('Albumin_and_Globulin_Ratio')
add_stat_annotations('Dataset_str', 'Albumin_and_Globulin_Ratio', axes[2, 0])

sns.boxplot(x=df_foie['Dataset_str'], y=df_foie['fact_Gender'], ax=axes[2, 1])
axes[2, 1].set_title('fact_Gender')
add_stat_annotations('Dataset_str', 'fact_Gender', axes[2, 1])


plt.show()

"""Toutes les comparaisons sont statistiquement tres significatives hormis l'age qui est un peu moins significative que les autres mais ok quand même.

Il reste la variable genre qui n'est pas statistiquement significative (ns)
"""

df_foie['Dataset'].value_counts()

"""# Création d'un nouveau df avec cible rééquilibrée"""

X = df_foie.drop(['Dataset', 'Dataset_str', 'Gender'], axis=1)
y = df_foie['Dataset']

# Diviser le jeu de données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Méthode 1 : RandomOverSampler
ros = RandomOverSampler(random_state=42)
X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)
model_ros = RandomForestClassifier(random_state=42)
model_ros.fit(X_train_ros, y_train_ros)
y_pred_ros = model_ros.predict(X_test)
print("Classification Report RandomOverSampler:\n", classification_report(y_test, y_pred_ros))

# Méthode 2 : SMOTE
smote = SMOTE(random_state=42)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
model_smote = RandomForestClassifier(random_state=42)
model_smote.fit(X_train_smote, y_train_smote)
y_pred_smote = model_smote.predict(X_test)
print("Classification Report SMOTE:\n", classification_report(y_test, y_pred_smote))

# Méthode RandomOverSampler

X = df_foie.drop(['Dataset','Dataset_str'], axis=1)
y = df_foie['Dataset']

# Diviser le jeu de données en ensembles d'entraînement et de test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Initialiser le sur-échantillonneur
ros = RandomOverSampler(random_state=42)

# Appliquer le sur-échantillonnage
X_resampled, y_resampled = ros.fit_resample(X, y)

# Nouveau DataFrame avec les données sur-échantillonnées
df_foie_reajuste = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='Dataset')], axis=1)

df_foie_reajuste.info()

plt.figure(figsize=(8, 6))
sns.heatmap(df_foie_reajuste.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=.5)

plt.show()

df_foie_reajuste['Dataset']  = df_foie_reajuste['Dataset'] .replace({ 2: 0})
df_foie_reajuste.info()

df_foie_reajuste['Dataset'].value_counts()

df_foie_reajuste.to_csv('dataset_foie_ML.csv', index = False)

"""# ML sur dataset rééquilibrée

## Pycaret
"""

pip install pycaret

from pycaret.classification import *

clf1 = setup(data=df_foie_reajuste, target='Dataset', session_id = 123)

best = compare_models()

"""## Choix des variables"""

X = df_foie_reajuste[['Age','Total_Bilirubin','Alkaline_Phosphotase', 'Alamine_Aminotransferase','Albumin_and_Globulin_Ratio']]
y = df_foie_reajuste['Dataset']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size = 0.75)

print("The length of the initial dataset is :", len(X))
print("The length of the train dataset is   :", len(X_train))
print("The length of the test dataset is    :", len(X_test))

"""## Boucle avec scaler et ML de classification"""

list_scalers = [MaxAbsScaler(), QuantileTransformer(), PowerTransformer(),
               MinMaxScaler(), StandardScaler(), RobustScaler()]

##liste des modèles utilisés
list_models = [
    KNeighborsClassifier(),
    DecisionTreeClassifier(),
    LogisticRegression(),
    ExtraTreesClassifier(),
    RandomForestClassifier(),
    GradientBoostingClassifier(),
    AdaBoostClassifier(),
    XGBClassifier(),
    LGBMClassifier(verbose=-1),
    LinearSVC(),
    NuSVC(),
    SVC(),
    GaussianNB()
]

#double boucle
results = []
for model in list_models:

    for scaler in list_scalers:

        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        model.fit(X_train_scaled, y_train)

        accuracy_train = model.score(X_train_scaled, y_train)
        accuracy_test = model.score(X_test_scaled, y_test)

        y_pred_test = model.predict(X_test_scaled)

        recall_test = recall_score(y_test, y_pred_test)
        overfitting = (model.score(X_train_scaled, y_train) - model.score(X_test_scaled, y_test))

        scores = cross_val_score(model, X_train_scaled, y_train, scoring='recall', cv=5)
        avg_scores = scores.mean()

        confusion_mat = confusion_matrix(y_test, y_pred_test)
        matrice = pd.DataFrame(data = confusion_mat,
                 index = model.classes_ ,
                 columns = model.classes_)

        results.append((model.__class__.__name__, scaler.__class__.__name__, accuracy_train, accuracy_test, recall_test, overfitting, avg_scores, matrice))

#tris de la liste results en fonction de la moyenne des scores de croos_validation, puis du recall_test, puis de l'accuracy test
sorted_results = sorted(results, key=lambda x: (x[6], x[4], x[3]), reverse=True)

for model, scaler, accuracy_train, accuracy_test, recall_test, overfitting, avg_scores, matrice in sorted_results:
    print("___________________________")
    print(f"Model: {model}")
    print(f"Scaler: {scaler}")
    print(f"Avg scores - cross validation : {avg_scores}")
    print(f"Accuracy Train: {accuracy_train}")
    print(f"Accuracy Test: {accuracy_test}")
    print(f"Recall Test: {recall_test}")
    print(f"Overfitting: {overfitting}")
    print(matrice)

"""J'ai fait le choix du modele ExtraTreesClassifier avec le QuantileTransformer. C'est le modele qui me donne le meilleur recall et accuracy.

## Cross Validation sur le ExtraTreeClassifier
"""

model = ExtraTreesClassifier()
scaler = QuantileTransformer()
X_train_scaled = scaler.fit_transform(X_train)
model.fit(X_train_scaled, y_train)
X_test_scaled = scaler.transform(X_test)

metrics = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='recall')

metrics

metrics.mean()

metrics.std()

"""## RandomSearchCV sur le ExtraTreeClassifier"""

dico = {'max_depth' : range(1,51), 'min_samples_leaf' : range(1,16), 'min_samples_split' : [2,5,7,10,15,30]}
rando = RandomizedSearchCV(ExtraTreesClassifier(), dico , cv=5, n_iter = 100)
rando.fit(X_train_scaled,y_train)

#meilleures valeurs des hyperparamètres
print(f"Best accuracy score: {rando.best_score_:.5f}")
print(f"Best parameters: {rando.best_params_}")
print(f"Best estimator: {rando.best_estimator_}")

"""## Modele ExtraTreeClassifier avec best parametres"""

#Random Search
best_model_ETC = ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=35, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=None, oob_score=False,
                     random_state=None, verbose=0, warm_start=False)
X_train_scaled_ETC = scaler.fit_transform(X_train)
best_model_ETC.fit(X_train_scaled_ETC, y_train)
X_test_scaled_ETC = scaler.transform(X_test)

y_pred_ETC = best_model_ETC.predict(X_test_scaled_ETC)
accuracy_ETC = accuracy_score(y_test, y_pred_ETC)
recall_ETC = recall_score(y_test, y_pred_ETC)
confusion_mat_ETC = confusion_matrix(y_test, y_pred_ETC)
scores = cross_val_score(best_model_ETC, X_train_scaled_ETC, y_train, scoring='recall', cv=5)
avg_scores_ETC = scores.mean()
print("Metrics for RandomSearch Model:")
print(f"Avg scores - cross validation : {avg_scores_ETC:.4f}")
print(f"Accuracy: {accuracy_ETC:.4f}")
print(f"Recall: {recall_ETC:.4f}")

"""## Test predict"""

for n in [0.4,6.2,3.04,0.31,0.53,5.23,2.83,0.64]:
    print(np.expm1(n))

non_malade_1 = [60, 0.49 , 492, 19.9, 0.36]
non_malade_2 = [65, 0.7, 186, 15.95, 0.9]

my_data = np.array([non_malade_1, non_malade_2]).reshape(2,5)
df_data = pd.DataFrame(my_data, columns = [['Age','Total_Bilirubin','Alkaline_Phosphotase', 'Alamine_Aminotransferase','Albumin_and_Globulin_Ratio']])
df_data

best_model_ETC = ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=35, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=None, oob_score=False,
                     random_state=None, verbose=0, warm_start=False)
X_train_scaled_ETC = scaler.fit_transform(X_train)
best_model_ETC.fit(X_train_scaled_ETC, y_train)
X_test_scaled_ETC = scaler.transform(df_data)

y_pred_ETC = best_model_ETC.predict(X_test_scaled_ETC)
y_pred_ETC

proba = best_model_ETC.predict_proba(X_test_scaled_ETC)
proba

proba[0,0]

proba[1,1]

"""## Feature_importance"""

result = permutation_importance(best_model_ETC, X_train_scaled_ETC, y_train, n_repeats=10, random_state=42)

feature_importance_ETC = pd.DataFrame({'Feature': X.columns, 'Importance': result.importances_mean})
feature_importance_ETC = feature_importance_ETC.sort_values('Importance', ascending=True)

feature_importance_ETC.plot(x='Feature', y='Importance', kind='barh', figsize=(10, 10))
plt.title('Feature Importance for ETC with QuantileTransformer')
plt.show()

"""## LASSO CV"""

reg = LassoCV()
reg.fit(X_train_scaled_ETC, y_train)

#print("Best alpha using built-in LassoCV: %f" % reg.alphas_)
print("Best score using built-in LassoCV: %f" %reg.score(X_train_scaled_ETC,y_train))
coef = pd.Series(reg.coef_, index = X_train.columns)
print("Lasso picked " + str(sum(coef != 0)) + " variables and eliminated the other " +  str(sum(coef == 0)) + " variables")

fig = plt.figure(figsize=(6,6))
imp_coef = coef.sort_values()
plt.rcParams['figure.figsize'] = (8.0, 10.0)
imp_coef.plot(kind = "barh")
plt.axvline(x=0, color='g')
plt.title("Importance des variables en utilisation un modèle Lasso")
fig.savefig('importance_graph.png', dpi=200, bbox_inches = 'tight') ;

"""## SHAP"""

# Convertir le résultat en DataFrame avec les noms de colonnes
X_test_shape = pd.DataFrame(X_test_scaled_ETC, columns=list(X_test.columns))
X_train_shape = pd.DataFrame(X_train_scaled_ETC, columns=list(X_train.columns))

explainer = shap.KernelExplainer(best_model_ETC.predict,shap.sample(X_test_shape,100))

shap_values = explainer.shap_values(X_test_shape,nsamples=100)

shap.summary_plot(shap_values,X_test_shape)

shap.initjs()
num_test = 2
fig = plt.figure(figsize=(20,10))
shap.force_plot(explainer.expected_value, shap_values[num_test,:], X_test_scaled[num_test,:].round(3), feature_names=X.columns, matplotlib=True, show=True)
plt.savefig('force_plot.png')







"""# DEEP LEARNING RESEAU DE NEURONNE

"""

QTscaler = QuantileTransformer()

X = df_foie_reajuste[['Age','Total_Bilirubin','Alkaline_Phosphotase', 'Alamine_Aminotransferase','Albumin_and_Globulin_Ratio']]
y = df_foie_reajuste['Dataset']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size = 0.75)

X_train_scaled = QTscaler.fit_transform(X_train)
X_test_scaled = QTscaler.transform(X_test)

print(X_train_scaled.shape)

"""## Keras"""

modelK = Sequential()

#modelMLP.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))
#modelMLP.add(Dense(32, activation='relu'))
#modelMLP.add(Dense(1, activation='sigmoid'))

modelK.add(Dense(64,activation='relu'))
modelK.add(Dropout(0.2))

modelK.add(Dense(32,activation='relu'))
modelK.add(Dropout(0.2))

modelK.add(Dense(16,activation='relu'))

modelK.add(Dense(1,activation='sigmoid'))

modelK.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy','Recall'])
#modelMLP.compile(optimizer=Adam(), loss='binary_crossentropy')

#early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=9)

modelK.fit(X_train_scaled, y_train, epochs=40, validation_data=[X_test_scaled, y_test], validation_split=0.2)

loss, accuracy ,recall = modelK.evaluate(X_test_scaled, y_test)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Recall: {recall:.4f}")

"""## MLP via skleanr + optim hyperparametres

"""

param_grid = {
    'hidden_layer_sizes': [(64,), (128,), (256,)],
    'activation': ['relu', 'tanh', 'sigmoid'],
    'learning_rate_init': [0.001, 0.01, 0.1]
}

mlp_model = MLPClassifier(max_iter=1000)

def custom_scorer(y_true, y_pred):
    recall = recall_score(y_true, y_pred)
    accuracy = accuracy_score(y_true, y_pred)
    # Poids arbitraire pour favoriser le recall
    return 0.8 * recall + 0.2 * accuracy

grid_search = GridSearchCV(mlp_model, param_grid, cv=3, scoring='recall', verbose=1)
grid_search.fit(X_train_scaled, y_train)

print("Meilleurs hyperparamètres:", grid_search.best_params_)

final_model = grid_search.best_estimator_

y_pred = final_model.predict(X_test_scaled)

final_recall = recall_score(y_test, y_pred)
final_accuracy = accuracy_score(y_test, y_pred)

print("Recall sur l'ensemble de test:", final_recall)
print("Accuracy sur l'ensemble de test:", final_accuracy)





